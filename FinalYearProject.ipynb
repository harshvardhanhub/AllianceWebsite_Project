{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "cell_execution_strategy": "setup",
      "collapsed_sections": [
        "tWE5LhxMwkdd",
        "hoF66kanDz1p",
        "ZSs6dtneEsVu",
        "D8PX4E1EE5QG",
        "dBt6ePEmFaaW",
        "gb65gtPBGEsG",
        "eYF8AC7BHBS0",
        "0SKU8iNXINYi",
        "On1S3FAEMoXT",
        "oY26L5oIOEXS",
        "_VebWEdYPTZL",
        "Vjc7gcsaVVPF"
      ],
      "authorship_tag": "ABX9TyPmUwU8Pyo9Yv+QcTzTJ9Qs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harshvardhanhub/AllianceWebsite_Project/blob/main/FinalYearProject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SCMOQZviBHoB"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import metrics\n",
        "\n",
        "import xgboost as xgb\n",
        "from xgboost import XGBClassifier\n",
        "from xgboost import plot_importance\n",
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **DEFINE**"
      ],
      "metadata": {
        "id": "tWE5LhxMwkdd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define additional classifiers\n",
        "random_forest_classifier = RandomForestClassifier()\n",
        "svm_classifier = SVC()\n",
        "logistic_regression_classifier = LogisticRegression()\n"
      ],
      "metadata": {
        "id": "fPQ29SNxCa01"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a dictionary of classifiers\n",
        "classifiers = {\n",
        "    'Decision Tree': DecisionTreeClassifier(),\n",
        "    'AdaBoost': AdaBoostClassifier(),\n",
        "    'Gradient Boosting': GradientBoostingClassifier(),\n",
        "    'XGBoost': XGBClassifier(),\n",
        "    'Random Forest': random_forest_classifier,\n",
        "    'SVM': svm_classifier,\n",
        "    'Logistic Regression': logistic_regression_classifier\n",
        "}\n"
      ],
      "metadata": {
        "id": "uZTmrIDpCdBR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))"
      ],
      "metadata": {
        "id": "IssurJqFC_J0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dtypes = {\n",
        "        'ip'            : 'uint16',\n",
        "        'app'           : 'uint16',\n",
        "        'device'        : 'uint16',\n",
        "        'os'            : 'uint16',\n",
        "        'channel'       : 'uint16',\n",
        "        'is_attributed' : 'uint8',\n",
        "        'click_id'      : 'uint32'\n",
        "        }\n",
        "\n",
        "colnames=['ip','app','device','os', 'channel', 'click_time', 'is_attributed']\n",
        "\n",
        "train_sample = pd.read_csv('/content/train_sample.csv',dtype=dtypes,usecols=colnames)\n"
      ],
      "metadata": {
        "id": "A7Vpj4ByDPD-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "uju-B2hSDipH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_sample)"
      ],
      "metadata": {
        "id": "CboKKQLaDpFJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_sample.memory_usage()"
      ],
      "metadata": {
        "id": "kQbag2YaDrzc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# space used by training data\n",
        "print('Training dataset uses {0} MB'.format(train_sample.memory_usage().sum()/1024**2))"
      ],
      "metadata": {
        "id": "S_ZLUKApDtKM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_sample.head()"
      ],
      "metadata": {
        "id": "zGGV0xUSDvoN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Exploring the Data - Univariate Analysis**\n",
        "\n",
        "Let's now understand and explore the data. Let's start with understanding the size and data types of the train_sample data."
      ],
      "metadata": {
        "id": "hoF66kanDz1p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# look at non-null values, number of entries etc.\n",
        "# there are no missing values\n",
        "train_sample.info()"
      ],
      "metadata": {
        "id": "ol4W-E7XD4H1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Basic exploratory analysis\n",
        "\n",
        "# Number of unique values in each column\n",
        "\n",
        "def fraction_unique(x):\n",
        "    return len(train_sample[x].unique())\n",
        "\n",
        "number_unique_vals = {x : fraction_unique(x) for x in train_sample.columns}\n",
        "number_unique_vals"
      ],
      "metadata": {
        "id": "ydsbE6UED6P4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# All columns apart from click time are originally int type,\n",
        "# though note that they are all actually categorical\n",
        "train_sample.dtypes"
      ],
      "metadata": {
        "id": "RaXZ-_hKD8yM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are certain 'apps' which have quite high number of instances/rows (each row is a click). The plot below shows this."
      ],
      "metadata": {
        "id": "zezZhWkWEC6H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# distribution of 'app'\n",
        "# some 'apps' have a disproportionately high number of clicks (>15k), and some are very rare (3-4)\n",
        "plt.figure(figsize=(60,10))\n",
        "sns.countplot(x=\"app\",data=train_sample)\n"
      ],
      "metadata": {
        "id": "pNl3qj_0D_T8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# distribution of 'device'\n",
        "# this is expected because a few popular devices are used heavily\n",
        "plt.figure(figsize=(54, 8))\n",
        "sns.countplot(x=\"device\", data=train_sample)"
      ],
      "metadata": {
        "id": "-Bs-LYugEGM2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# channel: various channels get clicks in comparable quantities\n",
        "plt.figure(figsize=(100, 8))\n",
        "sns.countplot(x=\"channel\", data=train_sample)"
      ],
      "metadata": {
        "id": "Tn4MPiBlEIDH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# os: there are a couple commos OSes (android and ios?), though some are rare and can indicate suspicion\n",
        "plt.figure(figsize=(14, 8))\n",
        "sns.countplot(x=\"os\", data=train_sample)"
      ],
      "metadata": {
        "id": "2NFxREFyEJXT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's now look at the distribution of the target variable 'is_attributed'."
      ],
      "metadata": {
        "id": "c1gtdxmoEMjf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# target variable distribution\n",
        "100 * (train_sample['is_attributed'].astype('object').value_counts()/len(train_sample.index))"
      ],
      "metadata": {
        "id": "TE_H5NieENKH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "italicized textExploring the Data - Segmented Univariate Analysis"
      ],
      "metadata": {
        "id": "tRjTIkDVESaG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# plot the average of 'is_attributed', or 'download rate'\n",
        "# with app (clearly this is non-readable)\n",
        "\n",
        "app_target = train_sample.groupby('app').is_attributed.agg(['mean','count'])\n",
        "app_target"
      ],
      "metadata": {
        "id": "3KY2XSi8EPof"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is clearly non-readable, so let's first get rid of all the apps that are very rare (say which comprise of less than 20% clicks) and plot the rest"
      ],
      "metadata": {
        "id": "UJLsXEpQEVir"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "frequent_apps = train_sample.groupby('app').size().reset_index(name='count')\n",
        "frequent_apps = frequent_apps[frequent_apps['count']>frequent_apps['count'].quantile(0.80)]\n",
        "frequent_apps = frequent_apps.merge(train_sample,on='app',how='inner')\n",
        "frequent_apps.head()"
      ],
      "metadata": {
        "id": "CjotwJdzEWGY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "sns.countplot(y=\"app\", hue=\"is_attributed\", data=frequent_apps)"
      ],
      "metadata": {
        "id": "Gw0O0hXjEY6o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can do lots of other interesting ananlysis with the existing features. For now, let's create some new features which will probably improve the model."
      ],
      "metadata": {
        "id": "q5-fSdRaEo42"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature Engineering\n",
        "\n",
        "Let's now derive some new features from the existing ones. There are a number of features one can extract from click_time itself, and by grouping combinations of IP with other features."
      ],
      "metadata": {
        "id": "6IwzTumQEq-v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *** Datetime Based Features***"
      ],
      "metadata": {
        "id": "ZSs6dtneEsVu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating datetime variables\n",
        "# takes in a df, adds date/time based columns to it, and returns the modified df\n",
        "\n",
        "def timeFeatures(df):\n",
        "    # Derive new features using the click_time column\n",
        "    df['datetime'] = pd.to_datetime(df['click_time'])\n",
        "    df['day_of_week'] = df['datetime'].dt.dayofweek\n",
        "    df['day_of_year'] = df['datetime'].dt.dayofyear\n",
        "    df['month'] = df['datetime'].dt.month\n",
        "    df['hour'] =df['datetime'].dt.hour\n",
        "    return df\n"
      ],
      "metadata": {
        "id": "0kQwyMVCEtiw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating new datetime variables and dropping the old ones\n",
        "train_sample = timeFeatures(train_sample)\n",
        "train_sample.drop(['click_time','datetime'], axis=1, inplace=True)\n",
        "train_sample.head()\n"
      ],
      "metadata": {
        "id": "WjM0447aEvrA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# datatypes\n",
        "# note that by default the new datetime variables are int64\n",
        "train_sample.dtypes\n"
      ],
      "metadata": {
        "id": "-cFbFPu6ExFX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# memory used by training data\n",
        "print('Training dataset uses {0} MB'.format(train_sample.memory_usage().sum()/1024**2))"
      ],
      "metadata": {
        "id": "cb5mvYXnEydo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# lets convert the variables back to lower dtype again\n",
        "int_vars = ['app', 'device', 'os', 'channel', 'day_of_week','day_of_year', 'month', 'hour']\n",
        "train_sample[int_vars] = train_sample[int_vars].astype('uint16')"
      ],
      "metadata": {
        "id": "gITB0e2qE0Ps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_sample.dtypes"
      ],
      "metadata": {
        "id": "X5u8qG6aE1X7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# space used by training data\n",
        "print('Training dataset uses {0} MB'.format(train_sample.memory_usage().sum()/1024**2))"
      ],
      "metadata": {
        "id": "KuzmBwyJE3T6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **IP Grouping Based Features**"
      ],
      "metadata": {
        "id": "D8PX4E1EE5QG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's now create some important features by grouping IP addresses with features such as os, channel, hour, day etc. Also, count of each IP address will also be a feature.\n",
        "\n",
        "Note that though we are deriving new features by grouping IP addresses, using IP adress itself as a features is not a good idea. This is because (in the test data) if a new IP address is seen, the model will see a new 'category' and will not be able to make predictions (IP is a categorical variable, it has just been encoded with numbers)."
      ],
      "metadata": {
        "id": "iNwKWNSEE8M3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# number of clicks by count of IP address\n",
        "# note that we are explicitly asking pandas to re-encode the aggregated features\n",
        "# as 'int16' to save memory\n",
        "ip_count = train_sample.groupby('ip').size().reset_index(name='ip_count').astype('int16')\n",
        "ip_count.head()\n"
      ],
      "metadata": {
        "id": "K6BhIkFfE-Pi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can now merge this dataframe with the original training df. Similarly, we can create combinations of various features such as ip_day_hour (count of ip-day-hour combinations), ip_hour_channel, ip_hour_app, etc.\n",
        "\n",
        "The following function takes in a dataframe and creates these features."
      ],
      "metadata": {
        "id": "3GPP8IRKFO_V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# creates groupings of IP addresses with other features and appends the new features to the df\n",
        "\n",
        "def grouped_features(df):\n",
        "    # ip_count\n",
        "    ip_count = df.groupby('ip').size().reset_index(name='ip_count').astype('uint16')\n",
        "    ip_day_hour = df.groupby(['ip','day_of_week','hour']).size().reset_index(name='ip_day_hour').astype('uint16')\n",
        "    ip_hour_channel = df[['ip','hour','channel']].groupby(['ip','hour','channel']).size().reset_index(name='ip_hour_channel').astype('uint16')\n",
        "    ip_hour_os = df.groupby(['ip', 'hour', 'os']).channel.count().reset_index(name='ip_hour_os').astype('uint16')\n",
        "    ip_hour_app = df.groupby(['ip', 'hour', 'app']).channel.count().reset_index(name='ip_hour_app').astype('uint16')\n",
        "    ip_hour_device = df.groupby(['ip', 'hour', 'device']).channel.count().reset_index(name='ip_hour_device').astype('uint16')\n",
        "\n",
        "    # merge the new aggregated features with the df\n",
        "    df = pd.merge(df, ip_count, on='ip', how='left')\n",
        "    del ip_count\n",
        "    df = pd.merge(df, ip_day_hour, on=['ip', 'day_of_week', 'hour'], how='left')\n",
        "    del ip_day_hour\n",
        "    df = pd.merge(df, ip_hour_channel, on=['ip', 'hour', 'channel'], how='left')\n",
        "    del ip_hour_channel\n",
        "    df = pd.merge(df, ip_hour_os, on=['ip', 'hour', 'os'], how='left')\n",
        "    del ip_hour_os\n",
        "    df = pd.merge(df, ip_hour_app, on=['ip', 'hour', 'app'], how='left')\n",
        "    del ip_hour_app\n",
        "    df = pd.merge(df, ip_hour_device, on=['ip', 'hour', 'device'], how='left')\n",
        "    del ip_hour_device\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "ldPLUHBiFPgR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_sample = grouped_features(train_sample)\n"
      ],
      "metadata": {
        "id": "2HDMtMGMFSYT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_sample.head()\n"
      ],
      "metadata": {
        "id": "FNRUHtr0FToW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Training dataset uses {0} MB'.format(train_sample.memory_usage().sum()/1024**2))"
      ],
      "metadata": {
        "id": "A_jVatPzFVHZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "# garbage collect (unused) object\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "iPB_3FDDFYEm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Modelling**"
      ],
      "metadata": {
        "id": "dBt6ePEmFaaW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's now build models to predict the variable is_attributed (downloaded). We'll try the several variants of boosting (adaboost, gradient boosting and XGBoost), tune the hyperparameters in each model and choose the one which gives the best performance.\n",
        "\n",
        "In the Kaggle competition, the metric for model evaluation is area under the ROC curve."
      ],
      "metadata": {
        "id": "bhhm5gSoFbw5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create x and y train\n",
        "X = train_sample.drop('is_attributed',axis=1)\n",
        "y = train_sample[['is_attributed']]\n",
        "\n",
        "# split data into train and test/validation sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.20,random_state=101)\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "id": "w1ZYbTLtFdZm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check the average download rates in train and test data, should be comparable\n",
        "print(y_train.mean())\n",
        "print(y_test.mean())"
      ],
      "metadata": {
        "id": "-YPT-mIAFfXx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **AdaBoost Classifier**"
      ],
      "metadata": {
        "id": "gb65gtPBGEsG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# adaboost classifier with max 600 decision tress of depth=2\n",
        "# learning_rate/shrinkage = 1.5\n",
        "\n",
        "# base estimator\n",
        "tree = DecisionTreeClassifier(max_depth=2)\n",
        "\n",
        "# adaboost with the tree as base estimator\n",
        "adaboost_model_1 = AdaBoostClassifier(base_estimator=tree,\n",
        "                                     n_estimators=600,\n",
        "                                     learning_rate=1.5,\n",
        "                                     algorithm=\"SAMME\")"
      ],
      "metadata": {
        "id": "No9hoHPZGGGO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fit\n",
        "adaboost_model_1.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "cgca9C4HGHyq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# predictions\n",
        "# the second column represents the probability of click resulting in a download\n",
        "\n",
        "predictions = adaboost_model_1.predict_proba(X_test)\n",
        "predictions[:10]"
      ],
      "metadata": {
        "id": "GXmb9VICGYMx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# metrics : AUC\n",
        "metrics.roc_auc_score(y_test,predictions[:,1])"
      ],
      "metadata": {
        "id": "BXr_y_YHGZiP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **AdaBoost - Hyperparameter Tuning**"
      ],
      "metadata": {
        "id": "eYF8AC7BHBS0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# parameter grid\n",
        "param_grid = {\"base_estimator__max_depth\" : [2,5],\n",
        "             \"n_estimators\" : [200,400,600]\n",
        "             }"
      ],
      "metadata": {
        "id": "iVOO91skHEqK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# base estimator\n",
        "tree = DecisionTreeClassifier()\n",
        "\n",
        "# adaboost with the tree as base estimator\n",
        "# learning rate is arbitrality set to 0.6\n",
        "\n",
        "ABC = AdaBoostClassifier(base_estimator=tree,\n",
        "                        learning_rate=0.6,\n",
        "                        algorithm=\"SAMME\")"
      ],
      "metadata": {
        "id": "sK80jffXHHwj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# run grid search\n",
        "folds = 3\n",
        "grid_search_ABC = GridSearchCV(ABC,\n",
        "                              cv=folds,\n",
        "                              param_grid=param_grid,\n",
        "                              scoring='roc_auc',\n",
        "                              return_train_score=True,\n",
        "                              verbose=1)"
      ],
      "metadata": {
        "id": "2rC57H5FHJx6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fit\n",
        "grid_search_ABC.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "fdsWaGBhHLE7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cv results\n",
        "cv_results = pd.DataFrame(grid_search_ABC.cv_results_)\n",
        "cv_results"
      ],
      "metadata": {
        "id": "U8pLMDK-HNXO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plotting AUC with hyperparameter combinations\n",
        "\n",
        "plt.figure(figsize=(16,6))\n",
        "for n, depth in enumerate(param_grid['base_estimator__max_depth']):\n",
        "\n",
        "\n",
        "    # subplot 1/n\n",
        "    plt.subplot(1,3, n+1)\n",
        "    depth_df = cv_results[cv_results['param_base_estimator__max_depth']==depth]\n",
        "\n",
        "    plt.plot(depth_df[\"param_n_estimators\"], depth_df[\"mean_test_score\"])\n",
        "    plt.plot(depth_df[\"param_n_estimators\"], depth_df[\"mean_train_score\"])\n",
        "    plt.xlabel('n_estimators')\n",
        "    plt.ylabel('AUC')\n",
        "    plt.title(\"max_depth={0}\".format(depth))\n",
        "    plt.ylim([0.60, 1])\n",
        "    plt.legend(['test score', 'train score'], loc='upper left')\n",
        "    plt.xscale('log')"
      ],
      "metadata": {
        "id": "zwfConkpHObf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The results above show that:\n",
        "\n",
        "The ensemble with max_depth=5 is clearly overfitting (training auc is almost 1, while the test score is much lower)\n",
        "At max_depth=2, the model performs slightly better (approx 95% AUC) with a higher test score\n",
        "\n",
        "Thus, we should go ahead with max_depth=2 and n_estimators=200.\n",
        "\n",
        "Note that we haven't experimented with many other important hyperparameters till now, such as learning rate, subsample etc., and the results might be considerably improved by tuning them. We'll next experiment with these hyperparameters."
      ],
      "metadata": {
        "id": "8FvTYGn4HSXp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model performance on test data with chosen hyperparameters\n",
        "\n",
        "# base estimator\n",
        "tree = DecisionTreeClassifier(max_depth=2)\n",
        "\n",
        "# adaboost with the tree as base estimator\n",
        "# learning rate is arbitrarily set, we'll discuss learning_rate below\n",
        "ABC = AdaBoostClassifier(\n",
        "    base_estimator=tree,\n",
        "    learning_rate=0.6,\n",
        "    n_estimators=200,\n",
        "    algorithm=\"SAMME\")\n",
        "\n",
        "ABC.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "A-AczOXjHT2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# predict on test data\n",
        "predictions = ABC.predict_proba(X_test)\n",
        "predictions[:10]"
      ],
      "metadata": {
        "id": "LmgW1i_aHVeh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# roc auc\n",
        "metrics.roc_auc_score(y_test, predictions[:, 1])"
      ],
      "metadata": {
        "id": "KbI4XRyYHWct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Gradient Boosting Classifier**"
      ],
      "metadata": {
        "id": "0SKU8iNXINYi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# parameter grid\n",
        "param_grid = {\"learning_rate\": [0.2, 0.6, 0.9],\n",
        "              \"subsample\": [0.3, 0.6, 0.9]\n",
        "             }"
      ],
      "metadata": {
        "id": "saBsHDoZIOTO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# adaboost with the tree as base estimator\n",
        "GBC = GradientBoostingClassifier(max_depth=2, n_estimators=200)"
      ],
      "metadata": {
        "id": "e60FGkqzLW1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# run grid search\n",
        "folds = 3\n",
        "grid_search_GBC = GridSearchCV(GBC,\n",
        "                               cv = folds,\n",
        "                               param_grid=param_grid,\n",
        "                               scoring = 'roc_auc',\n",
        "                               return_train_score=True,\n",
        "                               verbose = 1)\n",
        "\n",
        "grid_search_GBC.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "hYzdcO1CJMxR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv_results = pd.DataFrame(grid_search_GBC.cv_results_)\n",
        "cv_results.head()"
      ],
      "metadata": {
        "id": "0GUj1g4IJNxA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # plotting\n",
        "plt.figure(figsize=(16,6))\n",
        "\n",
        "\n",
        "for n, subsample in enumerate(param_grid['subsample']):\n",
        "\n",
        "\n",
        "    # subplot 1/n\n",
        "    plt.subplot(1,len(param_grid['subsample']), n+1)\n",
        "    df = cv_results[cv_results['param_subsample']==subsample]\n",
        "\n",
        "    plt.plot(df[\"param_learning_rate\"], df[\"mean_test_score\"])\n",
        "    plt.plot(df[\"param_learning_rate\"], df[\"mean_train_score\"])\n",
        "    plt.xlabel('learning_rate')\n",
        "    plt.ylabel('AUC')\n",
        "    plt.title(\"subsample={0}\".format(subsample))\n",
        "    plt.ylim([0.60, 1])\n",
        "    plt.legend(['test score', 'train score'], loc='upper left')\n",
        "    plt.xscale('log')"
      ],
      "metadata": {
        "id": "nXlRhHolJPgz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Instantiate the Gradient Boosting Classifier\n",
        "gb_classifier = GradientBoostingClassifier()\n",
        "\n",
        "# Fit the model on the training data\n",
        "gb_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "predictions_gb = gb_classifier.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy_gb = accuracy_score(y_test, predictions_gb)\n",
        "roc_auc_gb = roc_auc_score(y_test, predictions_gb)\n",
        "classification_report_gb = classification_report(y_test, predictions_gb)\n",
        "\n",
        "# Print the accuracy, ROC AUC, and classification report\n",
        "print(\"Gradient Boosting Classifier Accuracy:\", accuracy_gb)\n",
        "print(\"Gradient Boosting Classifier ROC AUC Score:\", roc_auc_gb)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report_gb)\n",
        "\n",
        "# Plot feature importance\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.barplot(x=gb_classifier.feature_importances_, y=X_train.columns)\n",
        "plt.title('Feature Importance Plot - Gradient Boosting Classifier')\n",
        "plt.xlabel('Feature Importance')\n",
        "plt.ylabel('Features')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "AgpzABnrJSZs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is clear from the plot above that the model with a lower subsample ratio performs better, while those with higher subsamples tend to overfit.\n",
        "\n",
        "Also, a lower learning rate results in less overfitting."
      ],
      "metadata": {
        "id": "rILKuFJbJRxP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **XGBoost (Extreme Gradient Boosting) Classifier**"
      ],
      "metadata": {
        "id": "On1S3FAEMoXT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# fit model on training data with default hyperparameters\n",
        "model = XGBClassifier()\n",
        "model.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "Y45Q4rLkMp2G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make predictions for test data\n",
        "# use predict_proba since we need probabilities to compute auc\n",
        "y_pred = model.predict_proba(X_test)\n",
        "y_pred[:10]"
      ],
      "metadata": {
        "id": "1zNmYcIaMtcQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate predictions\n",
        "roc = metrics.roc_auc_score(y_test,y_pred[:,1])\n",
        "print(\"AUC : %.2f%%\" %(roc * 100.0))"
      ],
      "metadata": {
        "id": "DBa9lBv8MuvC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The roc_auc in this case is about 0.95% with default hyperparameters. Let's try changing the hyperparameters\n",
        "\n",
        "Let's now try tuning the hyperparameters using k-fold CV. We'll then use grid search CV to find the optimal values of hyperparameters."
      ],
      "metadata": {
        "id": "CV6uBBFLMxX9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperparameter tuning with XGBoost\n",
        "# creating a KFold object\n",
        "folds = 3\n",
        "# specify range of hyperparamaters\n",
        "param_grid = {'learning_rate' : [0.2,0.6],\n",
        "             'subsample' : [0.3,0.6,0.9]\n",
        "             }\n",
        "# specify model\n",
        "xgb_model = XGBClassifier(max_depth=2,n_estimators=200)\n",
        "# set up GridSearchCV()\n",
        "model_cv = GridSearchCV(estimator = xgb_model,\n",
        "                       param_grid = param_grid,\n",
        "                       scoring = 'roc_auc',\n",
        "                       cv = folds,\n",
        "                       verbose = 1,\n",
        "                       return_train_score = True)"
      ],
      "metadata": {
        "id": "bCG3xFG-Myg2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fit the model\n",
        "model_cv.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "eeJcpgrrM0CG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cv results\n",
        "cv_results = pd.DataFrame(model_cv.cv_results_)\n",
        "cv_results"
      ],
      "metadata": {
        "id": "XAnuO102M1D3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert parameters to int for plotting on x-axis\n",
        "cv_results['param_learning_rate'] = cv_results['param_learning_rate'].astype('float')\n",
        "cv_results.head()"
      ],
      "metadata": {
        "id": "b1Z5oSXBM4ri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # plotting\n",
        "plt.figure(figsize=(16,6))\n",
        "\n",
        "param_grid = {'learning_rate': [0.2, 0.6],\n",
        "             'subsample': [0.3, 0.6, 0.9]}\n",
        "\n",
        "\n",
        "for n, subsample in enumerate(param_grid['subsample']):\n",
        "\n",
        "\n",
        "    # subplot 1/n\n",
        "    plt.subplot(1,len(param_grid['subsample']), n+1)\n",
        "    df = cv_results[cv_results['param_subsample']==subsample]\n",
        "\n",
        "    plt.plot(df[\"param_learning_rate\"], df[\"mean_test_score\"])\n",
        "    plt.plot(df[\"param_learning_rate\"], df[\"mean_train_score\"])\n",
        "    plt.xlabel('learning_rate')\n",
        "    plt.ylabel('AUC')\n",
        "    plt.title(\"subsample={0}\".format(subsample))\n",
        "    plt.ylim([0.60, 1])\n",
        "    plt.legend(['test score', 'train score'], loc='upper left')\n",
        "    plt.xscale('log')"
      ],
      "metadata": {
        "id": "M5WkxCQLM8eU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Instantiate the XGBoost classifier\n",
        "xgb_model = XGBClassifier()\n",
        "\n",
        "# Fit the model on the training data\n",
        "xgb_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "predictions_xgb = xgb_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy_xgb = accuracy_score(y_test, predictions_xgb)\n",
        "classification_report_xgb = classification_report(y_test, predictions_xgb)\n",
        "\n",
        "# Print the accuracy and classification report\n",
        "print(\"XGBoost Classifier Accuracy:\", accuracy_xgb)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report_xgb)\n"
      ],
      "metadata": {
        "id": "YkAsnN2fNW9I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Instantiate the XGBoost classifier\n",
        "xgb_model = XGBClassifier()\n",
        "\n",
        "# Fit the model on the training data\n",
        "xgb_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "predictions_xgb = xgb_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy_xgb = accuracy_score(y_test, predictions_xgb)\n",
        "roc_auc_xgb = roc_auc_score(y_test, predictions_xgb)\n",
        "classification_report_xgb = classification_report(y_test, predictions_xgb)\n",
        "\n",
        "# Print the accuracy, ROC AUC, and classification report\n",
        "print(\"XGBoost Classifier Accuracy:\", accuracy_xgb)\n",
        "print(\"XGBoost Classifier ROC AUC Score:\", roc_auc_xgb)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report_xgb)\n",
        "\n",
        "# Plot feature importance\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.barplot(x=xgb_model.feature_importances_, y=X_train.columns)\n",
        "plt.title('Feature Importance Plot - XGBoost')\n",
        "plt.xlabel('Feature Importance')\n",
        "plt.ylabel('Features')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "LVTWmp0_NYyh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Random Forest Classifier:**"
      ],
      "metadata": {
        "id": "oY26L5oIOEXS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "\n",
        "# Instantiate the Random Forest Classifier\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Fit the model on the training data\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "rf_predictions = rf_classifier.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
        "rf_roc_auc = roc_auc_score(y_test, rf_predictions)\n",
        "\n",
        "print(\"Random Forest Classifier Accuracy:\", rf_accuracy)\n",
        "print(\"Random Forest Classifier ROC AUC Score:\", rf_roc_auc)\n"
      ],
      "metadata": {
        "id": "d3BImCsHOCKg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot feature importances\n",
        "plt.figure(figsize=(10, 6))\n",
        "feat_importances = pd.Series(rf_classifier.feature_importances_, index=X_train.columns)\n",
        "feat_importances.nlargest(10).plot(kind='barh')\n",
        "plt.title('Top 10 Feature Importances')\n",
        "plt.xlabel('Relative Importance')\n",
        "plt.ylabel('Feature')\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "yxyPw5a5OIdN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "# Compute confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, rf_predictions)\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "CgkElLllOKeH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Support Vector Machine (SVM) Classifier**"
      ],
      "metadata": {
        "id": "_VebWEdYPTZL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "# Instantiate the SVM classifier\n",
        "svm_classifier = SVC(kernel='linear', random_state=42)\n",
        "\n",
        "# Fit the model on the training data\n",
        "svm_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "svm_predictions = svm_classifier.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "svm_accuracy = accuracy_score(y_test, svm_predictions)\n",
        "svm_roc_auc = roc_auc_score(y_test, svm_predictions)\n",
        "\n",
        "print(\"SVM Classifier Accuracy:\", svm_accuracy)\n",
        "print(\"SVM Classifier ROC AUC Score:\", svm_roc_auc)\n"
      ],
      "metadata": {
        "id": "hP3P9hyxPhLy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Confusion Matrix:"
      ],
      "metadata": {
        "id": "pey4xHXIVOfJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "# Calculate the confusion matrix\n",
        "cm = confusion_matrix(y_test, svm_predictions)\n",
        "\n",
        "# Plot confusion matrix heatmap\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "vR4ylvi4VB9Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Logistic Regression classifier:**"
      ],
      "metadata": {
        "id": "Vjc7gcsaVVPF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Instantiate the Logistic Regression classifier\n",
        "log_reg = LogisticRegression()\n",
        "\n",
        "# Fit the model on the training data\n",
        "log_reg.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "predictions_lr = log_reg.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy_lr = accuracy_score(y_test, predictions_lr)\n",
        "classification_report_lr = classification_report(y_test, predictions_lr)\n",
        "\n",
        "# Print the accuracy and classification report\n",
        "print(\"Logistic Regression Classifier Accuracy:\", accuracy_lr)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report_lr)\n"
      ],
      "metadata": {
        "id": "bv90h8qyYFEH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Confusion Matrix:"
      ],
      "metadata": {
        "id": "Jjnu1Yl_YMZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "# Calculate the confusion matrix\n",
        "cm = confusion_matrix(y_test, predictions_lr)\n",
        "\n",
        "# Plot confusion matrix heatmap\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "9bk2yzjOYGEB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}